# Unified Workflow Configuration
# Single YAML file for research topic, agents, workflow settings, and output config

# Research Topic Configuration
topic:
  topic: "Rapid Prototyping Frameworks for Physical AI in Dense Urban Environments"
  keywords: ["rapid prototyping", "physical AI", "robotics", "autonomous systems", "dense urban environments", "hardware prototyping", "software prototyping", "user-centered design", "deployment risk", "iteration cycles", "manufacturing systems", "autonomous vehicles"]
  domain: "robotics and autonomous systems"
  scope: "Focus on rapid prototyping methodologies (hardware + software) that enable faster iteration cycles for physical AI robots operating in dense urban environments, with emphasis on user-centered design principles to reduce deployment risk"
  research_question: "What rapid prototyping methodologies (hardware + software) enable 10x faster iteration cycles for physical AI robots operating in dense urban environments, and how do user-centered design principles reduce deployment risk?"
  context: "Physical AI is emerging as a #1 trend in 2026 (IBM, ABI Research reports). Dense urban environments like the SF Bay Area present unique challenges for physical AI robots, requiring rapid iteration cycles and user-centered design approaches. This research combines rapid prototyping expertise, robotics, and autonomous systems to create reusable frameworks with high industry adoption potential."

# Agent Configurations
# Model selection guide based on pricing research (2025):
#   Gemini 2.5 Flash-Lite ($0.10/1M input, $0.40/1M output): Bulk screening, high-volume classification - RECOMMENDED for full-text screening
#   Gemini 2.5 Flash ($0.30/1M input, $2.50/1M output): Balanced speed/cost - RECOMMENDED for search and moderate-volume tasks
#   Gemini 2.5 Pro ($1.25/1M input, $10.00/1M output): Quality-critical decisions - RECOMMENDED for borderline screening, extraction, writing
#   Gemini 3 Pro ($2.00/1M input, $12.00/1M output): Most advanced reasoning - OPTIONAL upgrade for Pro tasks
#   Perplexity: sonar-pro, sonar-reasoning-pro, sonar
agents:
  search_agent:
    role: "Literature Search Specialist"
    goal: "Find comprehensive literature on {topic} across multiple databases"
    backstory: "Expert researcher specializing in {domain} with deep knowledge of {topic}"
    # Flash: Optimized for speed, efficiency, and scale. Best price-performance for search tasks.
    # Handles large-scale summarization, responsive chat, efficient data extraction.
    llm_model: "gemini-2.5-flash"
    tools: ["database_search", "query_builder", "exa_search", "tavily_search"]
    temperature: 0.1
    max_iterations: 5
    
  # Title/Abstract Screening - uses Flash-Lite for maximum cost efficiency
  title_abstract_screener:
    role: "Title/Abstract Screening Specialist"
    goal: "Screen papers based on title and abstract for relevance to {topic} and {research_question}"
    backstory: "Expert reviewer with expertise in {domain}, focusing on {topic}. Handles borderline cases requiring careful judgment."
    # Flash-Lite: Best cost efficiency for classification tasks. 3x cheaper than Flash ($0.10 vs $0.30 input, $0.40 vs $2.50 output).
    # 12.5x cheaper than Pro ($0.10 vs $1.25 input, $0.40 vs $10.00 output).
    # Perfect for title/abstract screening where keyword pre-filtering handles most cases, but LLM is needed for uncertain papers.
    # Flash-Lite provides sufficient accuracy for classification tasks while minimizing costs.
    llm_model: "gemini-2.5-flash-lite"
    tools: ["title_screener"]
    temperature: 0.2
    max_iterations: 10
    
  # Full-text Screening - use Flash-Lite for bulk processing (89+ papers)
  fulltext_screener:
    role: "Full-text Screening Specialist"
    goal: "Screen papers based on full-text content for relevance to {topic} and {research_question}"
    backstory: "Efficient reviewer specializing in {topic}. Optimized for high-volume screening tasks."
    # Flash-Lite: Optimized for bulk screening tasks. 4x cheaper than Pro ($0.10 vs $1.25 per 1M tokens).
    # Suitable for high-volume classification where speed and cost matter more than nuanced reasoning.
    # Model selection guide:
    # - Flash-Lite ($0.10): Bulk screening, high-volume tasks (RECOMMENDED for full-text)
    # - Flash ($0.30): Balanced speed/cost for moderate volume
    # - Pro ($1.25): Quality-critical, low-volume decisions
    llm_model: "gemini-2.5-flash-lite"
    tools: ["fulltext_screener"]
    temperature: 0.2
    max_iterations: 5
    
  # DEPRECATED: Use title_abstract_screener and fulltext_screener instead
  # Kept for backward compatibility - will be used as fallback if new configs are missing
  screening_agent:
    role: "Screening Specialist"
    goal: "Screen papers for relevance to {topic} and {research_question}"
    backstory: "Meticulous reviewer with expertise in {domain}, focusing on {topic}"
    # Pro: Advanced reasoning for complex multi-step logic. Higher accuracy for precision-critical tasks.
    # Excels at complex reasoning, advanced coding, large data analysis with fewer errors.
    llm_model: "gemini-2.5-pro"
    tools: ["title_screener", "fulltext_screener"]
    temperature: 0.2
    max_iterations: 10
    
  extraction_agent:
    role: "Data Extraction Specialist"
    goal: "Extract structured data from papers related to {topic}"
    backstory: "Detail-oriented analyst specializing in {domain} research on {topic}"
    # Pro: Handles complex extraction with 90%+ accuracy. Better at structured output and complex reasoning.
    # Delivers more precise answers for technical tasks requiring structured data extraction.
    llm_model: "gemini-2.5-pro"
    tools: ["data_extractor"]
    temperature: 0.1
    max_iterations: 5
    
  introduction_writer:
    role: "Introduction Writer"
    goal: "Write compelling introduction for systematic review on {topic}"
    backstory: "Skilled academic writer with expertise in {domain}, specializing in {topic}"
    # Pro: Better for professional reports, strategic documents, analytical workflows.
    # Delivers more detailed explanations and polished outputs for academic writing.
    llm_model: "gemini-2.5-pro"
    tools: []
    temperature: 0.2
    max_iterations: 3
    
  methods_writer:
    role: "Methods Writer"
    goal: "Write detailed methods section for {topic} systematic review"
    backstory: "Methodology expert in {domain} research, focusing on {topic}"
    # Pro: Better for technical writing, code review, and structured documentation.
    # Handles complex logic and structured output better than Flash.
    llm_model: "gemini-2.5-pro"
    tools: []
    temperature: 0.2
    max_iterations: 3
    
  results_writer:
    role: "Results Writer"
    goal: "Synthesize and present results for {topic} systematic review"
    backstory: "Data synthesis expert in {domain}, specializing in {topic}"
    # Pro: Better for synthesizing large datasets, making sense of complex information.
    # Excels at data analysis and presenting insights from dense information.
    llm_model: "gemini-2.5-pro"
    tools: []
    temperature: 0.2
    max_iterations: 3
    
  discussion_writer:
    role: "Discussion Writer"
    goal: "Write comprehensive discussion for {topic} systematic review"
    backstory: "Critical analysis expert in {domain}, focusing on {topic}"
    # Pro: Best for critical analysis, complex reasoning, and nuanced interpretation.
    # Handles multi-step logic and provides deeper insights for discussion sections.
    llm_model: "gemini-2.5-pro"
    tools: []
    temperature: 0.2
    max_iterations: 3
    
  abstract_generator:
    role: "Abstract Generator"
    goal: "Generate concise abstract summarizing {topic} systematic review"
    backstory: "Expert academic writer specializing in {domain}, skilled at creating compelling abstracts"
    # Flash: Sufficient quality for abstract generation. Abstracts are shorter and less complex than full sections.
    # 60-75% cheaper than Pro ($0.30 vs $1.25 input, $2.50 vs $10.00 output).
    # Flash provides good quality for abstract generation while maintaining cost efficiency.
    llm_model: "gemini-2.5-flash"
    tools: []
    temperature: 0.2
    max_iterations: 3

# Workflow Settings
workflow:
  databases: ["PubMed", "arXiv", "Semantic Scholar", "Crossref", "ACM"]
  date_range:
    start: null  # null means no start limit
    end: 2025
  language: "English"
  max_results_per_db: 100
  similarity_threshold: 85  # For deduplication
  
  # Database-specific settings
  database_settings:
    PubMed:
      enabled: true
      max_results: 100
      rate_limit: 3  # requests per second
      requires_api_key: false  # Optional but recommended
    arXiv:
      enabled: true
      max_results: 100
      rate_limit: 3  # requests per second
      requires_api_key: false
    "Semantic Scholar":
      enabled: true
      max_results: 100
      rate_limit: 1  # requests per second (with API key)
      requires_api_key: false  # Optional but recommended for higher limits
    Crossref:
      enabled: true
      max_results: 100
      rate_limit: 10  # requests per second (conservative)
      requires_api_key: false
      requires_email: true  # Recommended
    Scopus:
      enabled: false  # Requires API key
      max_results: 100
      rate_limit: 9  # requests per second
      requires_api_key: true
    "Web of Science":
      enabled: false  # Requires API key
      max_results: 100
      rate_limit: 5
      requires_api_key: true
    "IEEE Xplore":
      enabled: false  # Requires API key
      max_results: 100
      rate_limit: 5
      requires_api_key: true
    ACM:
      enabled: true
      max_results: 100
      rate_limit: 2  # Conservative rate limit for web scraping
      requires_api_key: false
  
  # Caching settings
  cache:
    enabled: true
    ttl_hours: 24  # Time-to-live for cached results
    cache_dir: "data/cache"
  
  # Proxy settings
  proxy:
    enabled: false
    type: "none"  # Options: none, http, socks5, scraperapi, free
    http_proxy: "${HTTP_PROXY}"  # HTTP proxy URL (e.g., "http://proxy.example.com:8080")
    https_proxy: "${HTTPS_PROXY}"  # HTTPS proxy URL (defaults to http_proxy if not specified)
    scraperapi_key: "${SCRAPERAPI_KEY}"  # ScraperAPI key (required for scraperapi type)
    rotation_on_failure: true  # Rotate proxy on failure
    timeout: 5.0  # Timeout for proxy health checks (seconds)
  
  # Integrity checking settings
  integrity:
    enabled: true
    required_fields: ["title", "authors"]  # Fields that must be present
    action: "warn"  # Options: warn (log warning) or raise (raise exception)
  
  # Session management settings
  session:
    persistent: true  # Use persistent HTTP sessions with cookie handling
    cookie_jar: "data/cookies"  # Directory for storing cookies
  
  # Search logging (PRISMA compliance)
  search_logging:
    enabled: true
    log_dir: "data/outputs/search_logs"
    generate_prisma_report: true
    generate_csv_summary: true
  
# Inclusion/Exclusion Criteria
criteria:
  inclusion:
    - "Studies on rapid prototyping frameworks or methodologies"
    - "Focus on physical AI, robotics, or autonomous systems"
    - "Application in dense urban environments or similar complex settings"
    - "Integration of hardware and software prototyping"
    - "User-centered design principles or approaches"
    - "Evaluation of iteration cycles, development speed, or deployment risk"
    - "Published in English and peer-reviewed journals or conferences"
  exclusion:
    - "Studies focused only on software prototyping without hardware components"
    - "Studies focused only on hardware prototyping without software integration"
    - "Non-urban environments (e.g., industrial, agricultural, underwater)"
    - "Non-rapid prototyping approaches (traditional development cycles)"
    - "Opinion pieces or non-peer-reviewed sources"
    - "Conference abstracts without full papers"

# Screening Safeguards
screening_safeguards:
  minimum_papers: 10  # Minimum papers required to pass full-text screening
  enable_manual_review: true  # Pause workflow for manual review if threshold not met
  show_borderline_papers: true  # Show borderline papers for review

# Search Terms (will be merged with topic keywords if provided)
search_terms:
  rapid_prototyping: ["rapid prototyping", "rapid iteration", "prototyping methodologies", "hardware prototyping", "software prototyping", "iterative design", "agile prototyping"]
  physical_ai: ["physical AI", "embodied AI", "robotic AI", "autonomous robots", "physical intelligence", "robot learning"]
  dense_urban: ["dense urban environments", "urban robotics", "city environments", "urban navigation", "urban mobility", "autonomous vehicles"]
  iteration_cycles: ["iteration cycles", "development cycles", "design iteration", "rapid iteration", "faster iteration", "10x iteration"]
  user_centered_design: ["user-centered design", "human-centered design", "user experience", "UX design", "design thinking", "user research"]
  deployment_risk: ["deployment risk", "risk reduction", "safety deployment", "production deployment", "field deployment"]

# Protocol Registration
protocol:
  registered: false  # Set to true if protocol is registered
  registry: "PROSPERO"  # Options: "PROSPERO", "OSF", "Other"
  registration_number: ""  # Fill in if registered (e.g., "CRD42025XXXXXX")
  url: ""  # Fill in if registered (e.g., "https://www.crd.york.ac.uk/prospero/display_record.php?ID=CRD42025XXXXXX")

# Supplementary Materials
supplementary_materials:
  search_strategies: true  # Include full search strategies
  extracted_data: true  # Include extracted data
  analysis_code: false  # Include analysis code if available
  other_materials: []  # List any other supplementary materials

# Writing Configuration
writing:
  style_extraction:
    enabled: true                    # Enable/disable style pattern extraction
    model: "gemini-2.5-pro"          # LLM model for section extraction
    max_papers: null                 # Max papers to analyze (null = all eligible)
    min_papers: 3                    # Minimum papers required for pattern extraction
  
  humanization:
    enabled: true                    # Enable/disable humanization
    model: "gemini-2.5-pro"          # LLM model for humanization
    temperature: 0.3                  # Temperature for variation
    max_iterations: 2                # Max refinement iterations
    naturalness_threshold: 0.75      # Minimum naturalness score
    section_specific: true            # Use section-specific strategies

# Quality Assessment Configuration
quality_assessment:
  risk_of_bias_tool: "RoB 2"  # Options: "RoB 2", "ROBINS-I", "CASP"
  grade_assessment: true  # Enable GRADE certainty assessment
  template_path: "data/quality_assessments/{workflow_id}_assessments.json"  # Path template for assessment file

# Funding Information
funding:
  source: "No funding received"  # Update with actual funding source if applicable
  grant_number: ""  # Grant number if applicable
  funder: ""  # Funder name if applicable

# Conflicts of Interest
conflicts_of_interest:
  statement: "The authors declare no conflicts of interest."  # Update as needed

# Output Configuration
output:
  directory: "data/outputs"
  formats: ["markdown", "json", "bibtex", "ris"]  # ris: Research Information Systems format
  generate_prisma: true
  generate_charts: true

# Manubot Configuration
manubot:
  enabled: true  # Set to true to enable Manubot export
  output_dir: "manuscript"  # Relative to data/outputs/
  citation_style: "ieee"  # Options: "ieee", "apa", "nature", "plos", etc.
  auto_resolve_citations: true  # Automatically resolve citations from DOI/PMID
  generate_manubot_yaml: true  # Generate manubot.yaml configuration file

# Submission Package Configuration
submission:
  enabled: true  # Set to true to enable submission package generation
  default_journal: "ieee"  # Default journal for submission package
  generate_pdf: true  # Generate PDF manuscript
  generate_docx: true  # Generate Word document
  generate_html: true  # Generate HTML version
  include_supplementary: true  # Include supplementary materials
  validate_before_package: true  # Validate submission before packaging
