UNIVERSITÉ DU QUÉBEC À MONTRÉAL
IMPROVING CHATGPT’S EMOTIONAL INTELLIGENCE THROUGH PROMPT
ENGINEERING
DISSERTATION
PRESENTED
AS PARTIAL REQUIREMENT
TO THE MASTERS IN COMPUTER SCIENCE
BY
AHMED BELKHIR
NOVEMBER 2023

UNIVERSITÉ DU QUÉBEC À MONTRÉAL
AMÉLIORATION DE L’INTELLIGENCE ÉMOTIONNELLE DE CHATGPT AVEC LE
PROMPT ENGINEERING
MÉMOIRE
PRÉSENTÉ
COMME EXIGENCE PARTIELLE
DE LA MAÎTRISE EN INFORMATIQUE
PAR
AHMED BELKHIR
NOVEMBRE 2023

UNIVERSITÉ DU QUÉBEC À MONTRÉAL
Service des bibliothèques
Avertissement
La diffusion de ce mémoire se fait dans le respect des droits de son auteur, qui a signé
le formulaire Autorisation de reproduire et de diffuser un travail de recherche de cycles
supérieurs (SDU-522 – Rév.04-2020). Cette autorisation stipule que «conformément à
l’article 11 du Règlement no 8 des études de cycles supérieurs, [l’auteur] concède à
l’Université du Québec à Montréal une licence non exclusive d’utilisation et de
publication de la totalité ou d’une partie importante de [son] travail de recherche pour
des fins pédagogiques et non commerciales. Plus précisément, [l’auteur] autorise
l’Université du Québec à Montréal à reproduire, diffuser, prêter, distribuer ou vendre des
copies de [son] travail de recherche à des fins non commerciales sur quelque support
que ce soit, y compris l’Internet. Cette licence et cette autorisation n’entraînent pas une
renonciation de [la] part [de l’auteur] à [ses] droits moraux ni à [ses] droits de propriété
intellectuelle. Sauf entente contraire, [l’auteur] conserve la liberté de diffuser et de
commercialiser ou non ce travail dont [il] possède un exemplaire.»

ACKNOWLEDGEMENTS
I would like to express my deepest gratitude to my supervisor, Dr. Fatiha Sadat, for her invaluable
guidance, unwavering support, and expertise throughout the entire duration of my Master studies
at UQAM. She has been an excellent advisor and her insightful feedback and constructive criticism
have been instrumental in shaping the direction and quality of this dissertation work.
I would also like to thank all faculty members and academic staff of UQAM for the resources they
have provided throughout my academic journey and I also thank all the teachers of the computer
science department of UQAM for the quality of their teaching throughout my masters.
Mydeepgratitudegoesalsotomyfamilyandfriendsfortheirsupport,encouragement,andpatience
throughout this academic journey. Their confidence in my abilities and constant support have been
a source of strength and motivation.
Special thanks to the members of the jury for their interest in my work and for agreeing to examine
this dissertation and enrich it with their proposals.
I extend my sincere thanks to the members of the jury for accepting to evaluate my work and
for providing their valuable insights and evaluation. Their expertise and critical evaluation greatly
contribute to the overall quality and rigor of this thesis.
In conclusion, I am deeply grateful to all those who have contributed directly or indirectly to the
completion of this master’s thesis. Their support, guidance, and encouragement have played a vital
role in its success.
iii

TABLE OF CONTENTS
LIST OF FIGURES .................................................................................. vii
LIST OF TABLES ................................................................................... ix
LIST OF ACRONYMS ............................................................................... x
RÉSUMÉ .............................................................................................. xii
ABSTRACT .......................................................................................... xiii
INTRODUCTION .................................................................................... 1
0.1 Problem statement .............................................................................. 2
0.2 Objectives........................................................................................ 4
0.3 Contributions .................................................................................... 5
0.4 Dissertation Structure........................................................................... 6
CHAPTER 1 MAIN CONCEPTS ................................................................. 7
1.1 Introduction...................................................................................... 7
1.2 Chatbots ......................................................................................... 7
1.2.1 Definition ................................................................................ 7
1.2.2 Why use chatbots?...................................................................... 8
1.3 Simplified Chatbot Pipeline .................................................................... 11
1.4 Large Language models ......................................................................... 13
1.4.1 Word representation .................................................................... 13
1.4.2 The transformer architecture........................................................... 15
1.5 Emotional Intelligence .......................................................................... 18
1.5.1 Definition ................................................................................ 18
1.5.2 Emotion models ......................................................................... 18
1.6 Conclusion ....................................................................................... 20
CHAPTER 2 LITERATURE REVIEW .......................................................... 21
2.1 Introduction...................................................................................... 21
2.2 A Brief History of Chatbots .................................................................... 21
2.2.1 Rule-based and pattern-matching systems ............................................ 21
2.2.2 Retrieval-Based Systems................................................................ 22
2.2.3 Sequence-to-sequence models and Generative AI ..................................... 22
2.3 Chatbot Application Architecture.............................................................. 24
2.4 Prompt engineering and language models ..................................................... 26
iv

2.4.1 Prompt engineering ..................................................................... 26
2.4.2 Dialogue models......................................................................... 28
2.4.3 ChatGPT ................................................................................ 29
2.5 Emotions in conversational systems............................................................ 35
2.5.1 The importance of emotions in conversational systems .............................. 35
2.5.2 Challenges and techniques used for incorporating emotions into chatbots.......... 36
2.6 Conclusion ....................................................................................... 40
CHAPTER 3 METHODOLOGY AND IMPLEMENTATION .................................. 41
3.1 Introduction...................................................................................... 41
3.2 Emotion Classification .......................................................................... 41
3.2.1 About the ELECTRA Model........................................................... 42
3.2.2 Transfer learning ........................................................................ 42
3.2.3 Dataset................................................................................... 44
3.2.4 Fine-tuning .............................................................................. 47
3.3 Enhancing ChatGPT emotions via prompt engineering...................................... 50
3.3.1 Problem formulation .................................................................... 50
3.3.2 ChatGPT-A: The regular ChatGPT................................................... 50
3.3.3 ChatGPT-B: Emotion-Infused ChatGPT ............................................. 51
3.3.4 ChatGPT-C: the emotion-adapting ChatGPT........................................ 53
3.4 Conclusion ....................................................................................... 55
CHAPTER 4 EXPERIMENTS AND RESULTS ................................................. 57
4.1 Introduction...................................................................................... 57
4.2 Emotion classification........................................................................... 57
4.2.1 Evaluation Metrics ...................................................................... 57
4.2.2 Significance test ......................................................................... 59
4.2.3 Hyperparameters tuning................................................................ 60
4.2.4 Classification results .................................................................... 63
4.3 Empathy evaluation............................................................................. 70
4.3.1 Evaluation Dataset...................................................................... 70
4.3.2 ChatGPT-B vs. ChatGPT-A........................................................... 71
4.3.3 ChatGPT-C vs ChatGPT-A ........................................................... 76
4.3.4 Comparaisons to the SOTA Models ................................................... 82
v

4.4 Conclusion ....................................................................................... 85
CONCLUSION ........................................................................................ 87
APPENDIX A PUBLICATION .................................................................. 88
BIBLIOGRAPHY .................................................................................... 89
vi

LIST OF FIGURES
Figure 1.1 Search Results in Scopus, from 1966 to 2019 for the keywords “chatbot” or “con-
versation agent” or “conversational interface" (Adamopoulou et Moussiades, 2020a). ..... 9
Figure 1.2 Simplified chatbot pipeline.............................................................. 12
Figure 1.3 Plot of the projection of some word embeddings in a 3D space. The left and right
halves of the x-axis represent male and female words, respectively. Adult and youth
words are, respectively, in the top and bottom halves of the y-axis (Bandyopadhyay
et al., 2022). .................................................................................... 14
Figure 1.4 Word embeddings and analogy. ........................................................ 15
Figure 1.5 The transformer architecture (Vaswani et al., 2017).................................. 17
Figure 1.6 Plutchik’s wheel of emotions (Plutchik, 1980)......................................... 19
Figure 2.1 A general architecture design for chatbots (Adamopoulou et Moussiades, 2020a).. 25
Figure 2.2 How reinforcement learning from human feedback is used for ChatGPT (Zhou
et al., 2023). ..................................................................................... 31
Figure 3.1 An overview of replaced token detection (Clark et al., 2020). ....................... 43
Figure 3.2 Transfer learning illustration (Kamath et al., 2020). ................................. 44
Figure 3.3 A sample of the data from GoEmotions. .............................................. 45
Figure 3.4 Number of examples for each emotion category in the GoEmotions dataset........ 46
Figure 3.5 Illustration of the classifier architecture. .............................................. 48
Figure 3.6 ChatGPT-A has no emotions........................................................... 51
Figure 3.7 Illustration of emotion infusion approach: ChatGPT-B. ............................. 52
Figure 3.8 ChatGPT-B and ChatGPT-C have similar designs................................... 54
Figure 4.1 Histogram of token lengths in the Empathetic Dialogues dataset. .................. 62
vii

Figure 4.2 Classification confusion matrix. ........................................................ 69
Figure 4.3 ChatGPT-B vs. ChatGPT-A: average change in emotion probability............... 72
Figure 4.4 ChatGPT-A vs. ChatGPT-B emotion frequency...................................... 74
Figure 4.5 ChatGPT-B: Response emotion per user emotion. ................................... 75
Figure 4.6 ChatGPT-C vs. ChatGPT-A emotion frequency...................................... 78
Figure 4.7 ChatGPT-C: Response emotion per user emotion. ................................... 79
viii

LIST OF TABLES
Table 3.1 Distribution of the different emotion types in the GoEmotions Dataset. ............ 47
Table 4.1 True & False Positive & negative definitions........................................... 57
Table 4.2 Summary of the used hyperparameters. ................................................ 63
Table 4.3 The detailed emotion classification results.............................................. 65
Table 4.4 Our ELECTRA-based emotion classifier vs BERT-based classifier................... 66
Table4.5 Emotion-levelandaveragef1-scoresofourproposedELECTRA-basedmodelcom-
pared to other state-of-the-art models in (Cortiz, 2021) on the same GoEmotions dataset. 68
Table 4.6 Contingency table for ChatGPT-A and ChatGPT-B.................................. 77
Table 4.7 Contingency table for ChatGPT-C vs. ChatGPT-A................................... 81
Table 4.8 Benchmarking with other empathetic chatbots......................................... 83
Table 4.9 Reply examples from the different chatbot models..................................... 83
ix

LIST OF ACRONYMS
LLMs: Large Language Models.
HCI: Human-Computer Interaction.
BERT: Bidirectional Encoder Representations from Transformers.
NLP: Natural Language Processing.
RNNs: Recurrent Neural Networks.
RNN-LM: Recurrent Neural Networks Language Models.
ALICE: Artificial Linguistic Internet Computer Entity.
AIML: Artificial Intelligence Markup Language.
Seq2Seq: Sequence to Sequence.
LSTM: Long Short Term Memory.
UI: User interface.
NLG: Natural Language Generation.
RL: Reinforcement Learning.
RLHF: Reinforcement Learning from Human Feedback.
PPO: Proximal Policy Optimisation.
VAD: Valence, Arousal, and Dominance.
GAN: Generative Adversarial Networks.
ELECTRA: Efficiently Learning an Encoder that Classifies Token Replacements Accurately.
PPCA: Principal Preserved Component Analysis.
AUROC: Area Under the Receiver Operating Characteristic Curve.
GPU: Graphics Processing Unit.
x

SOTA: State-Of-The-Art.
AI: Artificial Intelligence.
CoT: Chain-of-Thought.
xi

RÉSUMÉ
Ce mémoire de maîtrise présente une étude sur l’amélioration des capacités émotionnelles des mod-
èles de langues conversationnels. Cette recherche étudie de nouvelles approches pour incorporer les
émotions dans les réponses des chatbots en utilisant le prompt engineering.
Ce travail est motivé par la demande croissante de chatbots émotionnellement intelligents qui peu-
vent engager les utilisateurs dans des conversations plus personnalisées et compatissantes. Pour
ce faire, deux contributions principales sont fournies. Tout d’abord, un classificateur d’émotions
précis basé sur le modèle ELECTRA est développé. Le classificateur est entraîné sur l’ensemble de
données GoEmotions. Il obtient des performances impressionnantes, avec un AUROC allant jusqu’à
98,5 %. Ce classificateur d’émotions fiable sert comme élément de base pour le reste de la recherche
et facilite l’analyse des émotions des utilisateurs et des chatbots.
Deuxièmement, de nouvelles méthodes d’infusion d’émotions utilisant le prompt engineering sont
proposées et évaluées. Les modèles de chatbot ChatGPT-B et ChatGPT-C sont conçus pour mod-
ifier leurs réponses en fonction des émotions de l’utilisateur, ce qui se traduit par des interactions
plus cohérentes sur le plan émotionnel. D’une part, ChatGPT-B prend en compte l’émotion de
l’utilisateur avant de générer des réponses à l’aide d’un classificateur d’émotions, et d’autre part,
ChatGPT-C tente de s’adapter à ce que ressent l’utilisateur sans aucune composante externe, en
s’appuyant uniquement sur l’ingénierie de l’invite pour améliorer les réponses au niveau émotionnel.
En analysant les réponses des deux versions modifiées proposées et en les comparant à la version
standard de ChatGPT (ChatGPT-A), nous constatons que l’utilisation du classificateur d’émotions
externe entraîne une utilisation plus fréquente et plus prononcée des émotions positives par rapport
à la version standard. En revanche, l’utilisation d’une simple ingénierie d’invite pour prendre en
compte l’émotion de l’utilisateur produit l’effet inverse. Enfin, les comparaisons avec des modèles
de chatbots émotionnels proposés dans la littérature mettent en évidence le potentiel du prompt
engineering pour améliorer les capacités émotionnelles des agents conversationnels basés sur les
modèles de langues larges.
Mots clés: Agents conversationnels, Chatbots, Modèles de langue larges, Apprentissage par trans-
fert, Intelligence émotionnelle
xii

ABSTRACT
This master thesis presents an exhaustive investigation into improving the emotive capabilities
of conversational language models. The research investigates novel approaches for incorporating
emotions into chatbot responses using prompt engineering.
The motivation behind our work is the increasing demand for emotionally intelligent chatbots that
can engage users in more personalized and compassionate conversations. To accomplish this, two
primary contributions are provided. First, an accurate emotion classifier built on top of the ELEC-
TRAmodelisdeveloped. TheclassifieristrainedontheGoEmotionsdatasetandobtainsimpressive
performance, withanAUROCofupto98.5%. Thisreliableemotionclassifierservesasafoundation
for the rest of the research and facilitates the analysis of user and chatbot emotions alike.
Second, newmethodsfor emotion infusionutilizingprompt engineering areproposedandevaluated.
The ChatGPT-B and ChatGPT-C chatbot models are designed to modify their responses based on
user emotions, resulting in more emotionally consistent interactions. On one hand, ChatGPT-B
takes the user’s emotion as input before generating responses using an emotion classifier, and on
the other hand, ChatGPT-C tries to accommodate for how the user feels without any external
component, relying only on prompt engineering to improve responses on the emotional level.
By analyzing responses of the two proposed altered versions and comparing them to the standard
version of ChatGPT (ChatGPT-A), we find that using the external emotion classifier leads to
more frequent and pronounced use of positive emotions compared to the standard version. On
the other hand, using simple prompt engineering to take the user emotion into consideration, does
the opposite. Finally, comparisons to the state-of-the-art models highlight the potential of prompt
engineering to enhance the emotional abilities of conversational agents based on large language
models.
Keywords: Conversationalagents, Chatbots, Largelanguagemodels, Transferlearning, Emotional
intelligence
xiii

INTRODUCTION
In the ever-changing landscape of technological innovation, the field of conversational systems and
chatbots has made remarkable strides in recent years, attracting the attention and enthusiasm of
not only devoted researchers and practitioners but also a broader range of individuals, including
non-specialists. Mainstream chatbot applications now range from customer service (Ando et Zhang,
2005) to education (Colace et al., 2018) and mental health therapy (Abd-Alrazaq et al., 2019). The
interest in these systems has been fueled by their 24/7, around-the-clock availability, their ever-
growing knowledge base, and, most importantly, their potential to chat with users in engaging and
fulfilling interactions by simulating human-like conversations and therefore attracting users from all
domains and needs.
Conversational agents have come a long way since the 1960s. Early chatbots relied on rigorous
rule-based systems, operating within predefined guidelines and predetermined responses. Later,
retrieval-based systems were developed, improving flexibility by accessing predefined databases of
responses,therebyenablingmorecontextuallyrelevantresponses. Thebreakthrough,however,came
with the introduction of modern generative models based on seq2seq (Sutskever et al., 2014) and
Transformers architecture (Vaswani et al., 2017), enabling convincingly natural conversation with
robots with impressive understanding capabilities.
However, even though modern chatbots can hold a meaningful conversations in natural language
and provide helpful information, there is still a gap that prevents a real bond between humans and
machines from being built, and it is about emotions. Modern conversational agents have limited
abilities when it comes to understanding, processing, and generating human-like and emotion-rich
conversations (Rapp et al., 2021; Belainine et al., 2020c; Belainine et al., 2020a). On the other
hand, emotion-aware chatbots have the potential to create more meaningful and empathetic conver-
sations, bridging the gap between human and AI and building rapport and trust in human-machine
interactions (Chen et al., 2021).
To address this challenge, this research at the intersection of chatbot technology, Artificial Intelli-
gence (AI), and emotion recognition explores the possibility of enhancing the emotional intelligence
of chatbots built on top of Large Language Models (LLMs) and enabling them to deliver more
1

emotionally engaging experiences.
More specifically, we investigate the effectiveness of incorporating external emotion classifiers and
prompt engineering (Reynolds et McDonell, 2021) to take into account the user’s emotional state
when generating responses by the ChatGPT (OpenAI, 2022) chatbot model. The emotion classifier
needs to be sensitive enough to discern even the slightest nuances in the user utterances in order to
providehelpfulinformationtotheChatGPTconversationallanguagemodelandsteeritaccordingly.
Prompt engineering is then used as a technique to inject emotional information into the chatbot
to make it more aware of the emotion of the user before generating replies, resulting in more
emotion-aware and human-like conversations with the same language model and without the need
for re-training or even fine-tuning.
0.1 Problem statement
This research is motivated by the increasing demand for sophisticated and emotionally intelligent
chatbot systems. While conversational agents have become increasingly prevalent in numerous do-
mains, such as customer service, virtual companionship, education, and healthcare, their capacity
to emotionally engage with users leaves to be desired. Emotions play a crucial role in human
communication, influencing how we express ourselves, comprehend others, and forge relationships.
Consequently, the incorporation of emotions into chatbot interactions has the potential to signifi-
cantly improve user experiences and the overall efficacy of these systems and convince more users
to use the new technology.
In recent studies, it has been shown that most people still prefer human-to-human interaction over
communicating with an artificial chatbot system and believe that a human can understand them
better (Rapp et al., 2021). This is because, while modern chatbot systems do answer questions
reliably in most cases, they fail to convey to users the feeling of talking to an actual human. This
is due to their inability to understand and respond to user emotions. Traditional chatbots often
provide impersonal and dispassionate responses, lacking humans’ natural empathy and emotional
awareness. By incorporating emotional intelligence into chatbots, we can bridge this gap and create
conversational agents that can alter their responses based on the user’s emotional states, leading to
conversations that are more engaging and empathetic and have a deeper resonance with users.
2

Moreover, this research intends to contribute to the fields of Natural Language Processing (NLP)
and AI by advancing the comprehension and modeling of emotions in human-machine interactions.
Emotions are complex and diverse, and capturing their nuances in computational models is a sig-
nificant challenge for researchers. By building a reliable emotion classifier, we can obtain insight
into both the emotional and the semantic information conveyed by the text data. This additional
information can be leveraged to incorporate emotions into chatbot systems effectively.
Due to the nuanced and complex character of human emotions, emotion recognition is consid-
ered a significant challenge in the field of NLP. Emotions are inherently complex because they
encompass a broad spectrum of feelings, expressions, and contextual variations that are frequently
intertwined with cultural, linguistic, and individual factors. Moreover, the scarcity of labeled emo-
tional data compounds the difficulty of training robust models from scratch. Thankfully, transfer
learning emerged as a promising solution, revolutionizing the landscape of emotion recognition in
NLP. Transfer learning employs pre-trained models on large and diverse text corpora to enable
the extraction of complex linguistic features and task-general contextual patterns. By fine-tuning
these pre-trained models on emotion-specific datasets, the obtained models can effectively learn
to recognize the subtle signals that indicate different emotions. This strategy capitalizes on the
general semantic knowledge acquired during pre-training. It adapts it to the specific nuances of
emotion recognition, resulting in improved accuracy and performance in identifying emotions from
text, which is essential for imbuing chatbot interactions with emotional intelligence. Therefore, this
research not only enhances our understanding of emotions but also contributes to the advancement
of conversational AI systems.
AsLLMscontinuetogrowinscaleandcomplexity,apersistentchallengehasemerged: thesignificant
resource burden associated with retraining such massive models. The process of retraining LLMs
in order to adapt to specific tasks or contexts has become increasingly resource-intensive, requiring
significant computational power, time, and money resources. This poses a substantial obstacle, par-
ticularly for researchers with limited access to advanced infrastructure. Even the more manageable
task of fine-tuning these models to achieve desired behaviors needs advanced resources that are not
within the reach of all researchers. Enter prompt engineering (Reynolds et McDonell, 2021), a new,
innovativeparadigmthatoffersacompellingsolutiontothisproblem. Unliketraditionalmethodsof
retraining and fine-tuning, prompt engineering provides a streamlined and effective way of guiding
3

and shaping the outputs of pre-trained language models. By designing carefully crafted prompts or
queries, researchers and developers can influence the behavior of these models without the need for
enormous resources.
Therefore, this research aims to advance the chatbot technology field by improving its emotional
intelligence. By addressing the limitations of existing chatbot systems and utilizing the power of
emotion recognition, we can create more engaging and human-like conversational agents that have
the potential to revolutionize human-machine interactions across multiple domains.
0.2 Objectives
The research in this master thesis seeks to improve the chatbot systems’ emotional intelligence so
they can engage in more empathetic and emotionally-aware conversations. In order to achieve this
goal, the following specific research objectives have been established:
• Develop an emotion classifier: Based on the ELECTRA model and a suitable emotion
dataset, develop an accurate and reliable emotion classifier. The classifier must be able to
detectandclassifyuseremotionsconveyedintextualinput,layingthegroundworkforemotion-
aware chatbot interactions.
• Integrate emotion modeling into ChatGPT: Improve the state-of-the-art ChatGPT
model with enhanced emotion capabilities. Explore various techniques, such as emotion in-
fusion and adaptation, to imbue ChatGPT with the capacity to comprehend and respond to
user emotions in a more personalized and context-appropriate manner.
• Evaluate and compare approaches: Conduct exhaustive tests to assess the performance
of the developed emotion classifier and the improved ChatGPT models. Evaluate the efficacy
of emotion prediction as well as the impact of emotion infusion and adaptation on the level of
empathy exhibited by the different chatbot versions.
• Compare with SOTA models: Compare the performance of the developed emotion-aware
ChatGPT models to that of other state-of-the-art emotion-aware chatbot models proposed in
the literature. Evaluate the advantages and disadvantages of various emotional responses in
terms of emotion precision and recall, as well as the fluency and coherence of the replies.
4

Thisresearchseekstoadvancechatbottechnologybyenhancingitsemotionalintelligenceandpaving
the way for more empathetic, engaging, and human-like interactions between chatbots and users.
0.3 Contributions
This master’s thesis presents two significant contributions intended to improve the emotional intel-
ligence of chatbot systems. The first contribution is the creation of an accurate emotion classifier,
andthesecondistheintroductionofnovelemotioninfusiontechniquesbasedonpromptengineering
techniques.
An emotion classifier based on the ELECTRA model is developed to resolve the limitations of
existent emotion detection models. The classifier detects and categorizes user emotions with high
precision, outperforming existing SOTA models and providing a solid foundation for emotion-aware
chatbot interactions. Using precision, recall, and F1-score metrics, the classifier’s performance is
proven to be reliable, both on an individual emotion level and on a general level.
Moreover, this dissertation presents novel emotion infusion techniques that utilize prompt engineer-
ingandanexternalemotionclassifiertoimprovetheemotionalexpressivenessofchatbots. Twonew
variants of the ChatGPT language model are presented: ChatGPT-B and ChatGPT-C. ChatGPT-
B incorporates the precise emotion of the user as input, resulting in more positive expressions of
emotion. ChatGPT-C, on the other hand, modifies its responses based on the user’s emotional
signals, with the goal of expressing a broader range of emotions, including negative ones, and foster-
ing empathy. Extensive experiments also prove that the accuracy, fluency, and coherence of these
methods’ emotional responses are superior.
This master thesis is built upon the foundation of a paper published in ACL ontology and pre-
sented at the 14th Conference RECENT ADVANCES IN NATURAL LANGUAGE PROCESSING
(RANLP 2023). It provides essential insights and findings relevant to the research presented in this
master thesis. See appendix section A.
5

0.4 Dissertation Structure
Chapter 1 sets the foundation for this research by providing an overview of the technologies utilized.
We begin by examining chatbots: what they actually are, and the reasons behind their growing
prominence. Exploring LLMs, we unravel their ability to understand context and represent words
and meanings. Additionally, we delve into some details of the transformer architecture before
introducing some emotion models, thus establishing a framework for understanding the different
dimensions and categories of emotions. This chapter establishes the groundwork for the subsequent
chapters, laying the foundation for integrating emotional intelligence into conversational systems.
Chapter2explorestheexistingliteratureonthetopic, providingacomprehensivereviewofresearch
and developments in conversational systems with a focus on emotional intelligence. We explore
the history of chatbot research and development, highlighting the challenges and opportunities in
enhancing emotional understanding in human-machine interactions. By analyzing prior approaches,
we identify gaps and constraints, aiming to find opportunities for further advancements in the field.
Chapter 3 presents our approach to enhancing the emotional capabilities of ChatGPT. We aim to
equip ChatGPT with emotional awareness to create more empathetic and emotionally intelligent
chatbots. We begin by developing an emotion classifier that shall allow for accurate recognition and
categorization of user emotions, serving as a crucial evaluation tool. Building upon this foundation,
we introduce three variants of ChatGPT that enable us to explore different approaches to infusing
emotional intelligence into chatbot conversations.
In Chapter 4, we present the results of our experiments in two parts. The first part focuses on
the evaluation of our emotion classifier, showcasing the classification metrics and the hyperparam-
eter tuning process that yielded impressive performance. The second part investigates the impact
of emotion infusion and adaptation on ChatGPT’s empathy level, comparing our approaches with
state-of-the-art models. We examine the emotional response accuracy and fluency of the different
ChatGPT variants, highlighting their strengths and contributions to enhancing emotional intelli-
gence.
Wefinishourworkwithasummarizingconclusionthatpresentsfutureperspectivesandimplications
of this research.
6

CHAPTER 1
MAIN CONCEPTS
1.1 Introduction
In this chapter, we set the foundation for the subsequent chapters of this dissertation by providing
background information on the main technologies utilized. We begin by delving into the world of
chatbots, providing definitions, and emphasizing why they have recently become a topic of growing
interest.
To comprehend the inner workings of chatbots, it is essential to familiarize ourselves with language
models. We explore how they understand the context and elucidate how they represent words and
meanings through advanced techniques. Moreover, we explore the complexities of transformer ar-
chitecture, a crucial element in the development of modern chatbot systems.
Emotions play an essential role in human-to-computer interactions, and their incorporation into
chatbot conversations has enormous potential. Therefore, we introduce the widely recognized emo-
tion models proposed by Ekman and Plutchik.
Explaining all these concepts will provide a solid foundation for understanding the rest of this
research and its contributions to enabling chatbots to carry on human-like conversations.
1.2 Chatbots
1.2.1 Definition
A chatbot is an interface model for Human-Computer Interaction (HCI) (Bansal et Khan, 2018).
The Oxford English Dictionary defines a chatbot as
"A computer program designed to simulate conversation with a human user, usually
over the internet; esp. one used to provide information or assistance to the user as part
of an automated service."
However, the term "conversational agent" is the more formal name for chatbots in scientific litera-
ture, and is defined as
7

"A dialogue system that can also understand and generate natural language content,
using text, voice, or hand gestures, such as sign language" (Allouch et al., 2021).
Throughout this thesis, we will be using both terms interchangeably.
In simple terms, a conversational agent is a software that can converse with a user in a natural
language like English or French (as opposed to artificial languages like programming languages) via
virtual chat rooms, websites, mobile apps, messaging applications or through the telephone. This
interface is slowly substituting many established graphical, purpose-specific user interfaces such as
web or mobile apps (Følstad et Brandtzæg, 2017).
Although the first chatbot dates back to 1966 (Weizenbaum, 1966), the interest in chatbots has
only exploded in recent years, especially after 2016 (Adamopoulou et Moussiades, 2020a). Some
researchers even called it the "chatbot tsunami" (Grudin et Jacques, 2019). This interest is likely
due to the improvements in computer processing power, the wide adoption of instant messaging ap-
plications, and the technological breakthroughs of recent years (see Figure 1.1). Another important
driving factor behind chatbots development has been the Loebner Prize, the annual competition for
conversational agents to identify the most human-like programs (Epstein, 1992), which led to the
development of systems that are more and more human-like.
1.2.2 Why use chatbots?
Chatbots have proven to be very useful. The interest mainly arose among tech giants such as
Google and Microsoft. Satya Nadella, Microsoft’s CEO declared that "Chatbots are the new apps"
(Marco della Cava, 2016). Chatbots today are being deployed across multiple industries to engage
with customers in business, patients in healthcare, or assist in education, to name but a few fields.
1.2.2.1 Chatbot applications
Incustomer service,chatbotsareaveryinterestingalternativetohumanagentsbecausemachines
can work 24 hours a day, seven days a week, and serve multiple customers at the same time. Also,
current chatbots are competent enough to keep customers happy to a certain extent. In fact,
a study (Luo et al., 2019) found that undisclosed chatbots are just as effective as experienced
8

Figure 1.1: Search Results in Scopus, from 1966 to 2019 for the keywords “chatbot” or
“conversation agent” or “conversational interface" (Adamopoulou et Moussiades, 2020a).
9

workers and four times more effective than inexperienced novice workers in terms of the number of
purchases. The same study indicates that revealing that the customer is being assisted by a chatbot
decreases the purchase rates significantly because machines are perceived as less knowledgeable and
less empathetic, even when they are not. Furthermore, according to Harvard Business Review, a
merefive-minutedelaycoulddecreaseabusiness’schancesofsellingtoacustomer, andaten-minute
delay could reduce their chances by 400% (Magazine, 2018).
In healthcare, chatbots can be used to diagnose simple diseases and provide information about
therapy and prevention. They represent a decent solution because research says 60% of visits to
doctors are for simple small-scale conditions, 80% of which can be cured at home using simple
home remedies (Bhirud et al., 2019). Chatbots were also used to help fight the covid-19 virus by
monitoring exposure to the virus, tracking infection symptoms, and combatting misinformation and
fake news (Almalki et Azeez, 2020).
Educationisanotherfieldinwhichchatbotsaremakingadifference. Infact, thescalabilityofsuch
24/7 systems makes them attractive as teacher replacements, even only for casual, simple questions.
In one case study, authors implemented a chatbot into the e-learning platform of the University of
Salerno to assist with two courses: Computer Science and Computer Networks (Colace et al., 2018).
There results were positive as over 70% of the suggestions provided by the chatbot were considered
correct by successful students. In addition to scalability, chatbots can be better than humans when
it comes to teaching foreign languages. A study (Haristiani, 2019) found that learners were more
confident talking and learning from chatbots compared to actual language teachers.
Chatbots proved to be interesting in other fields, too, including personal banking, food ordering
anddelivery, packagetracking, androbotics. Beyondpracticalapplicationsforchatbots, researchers
investigated the psychological reasons behind using such systems.
1.2.2.2 Psychological Reasons
In one of the first surveys to investigate the reasons for using chatbots, it turned out that there
are four main reasons behind the interest: productivity, entertainment, social needs, and curiosity
(Brandtzaeg et Følstad, 2017).
10

Using Uses and Gratifications theory (U&G) (Rubin, 2009), open questions in the survey revealed
that the most common reason for using chatbots is productivity. Users find that a chatbot can be
a fast and convenient way to obtain information online. It is in some way easier to just ask for the
information than to navigate the various graphical user interfaces to find simple answers.
Inadditiontoproductivity,somepeopleusechatbotsforentertainmentpurposes. Chatbots’answers
can be funny sometimes, especially if the user is bored or wants to kill time. Other users might be
lonely and feel the need for some kind of social interaction. The chatbots nowadays have become
so close to humans that it is possible to enjoy their company as a virtual friend in order to fulfill
social needs.
Furthermore, chatbotsarearelativelynewtechnologyforthemassmarket, andthisattractscurious
and risk-driven users who want to explore it and experiment with it.
1.3 Simplified Chatbot Pipeline
Chatbotsaremadeupofseveralcrucialparts,eachofwhichplaysaspecificroleandcooperateswith
the others to form a reliable system that successfully accomplishes its goal. According to (Bilquise
et al., 2022), we can organize these components in a pipeline based on the order of usage:
• Natural Language Processing unit: This is the component that processes the chatbot
inputusingNLPtechniquessuchastokenization,lemmatization,andstemming(Suhailiet al.,
2021).
• Natural Language Understanding: Typically,thiscomponentparsesstructureddatafrom
the NLP component to comprehend the user’s intent and any details related to that intent
(Cahn, 2017)
• Dialog Manager: Inordertodecidewhatactionshouldbetakennext, thedialoguemanager
component analyses the comprehensible structured data, maintains the dialogue framework,
such as the semantic frame, and encodes the data. If there are ambiguities about the user’s
needs, this component eventually asks further questions to resolve it (Adamopoulou et Mous-
siades, 2020b).
11

Figure 1.2: Simplified chatbot pipeline.
• Natural Language Generator: This is the component that may be retrieval-based, rule-
based, or generative. It is responsible for how the chatbot generates responses based on
information from previous components.
12

Additionally, recentdevelopmentsinNLPhavecompletelyrevolutionizedthechatbotindustry. One
of the most important developments is the advent of large language models.
1.4 Large Language models
Large Language Models (LLMs) have had a substantial impact on the capabilities and functionality
of modern chatbots. These models have revolutionized the way chatbots comprehend and provide
human-like answers. They were trained on enormous volumes of text data and strengthened using
deep learning techniques.
In order to have a basic understanding of LLMs’ significance and how they work, we provide a brief
explanation of important aspects:
1.4.1 Word representation
Language models use "word embeddings" or word vectors to represent words and meanings in a
high-dimensional space. Word embeddings are dense numerical representations that identify the
semantic connections between words based on how frequently they appear together in a text corpus.
The development of Word2Vec in 2013 (Mikolov et al., 2013) revolutionized word embeddings by
proposing a shallow neural network model capable of learning continuous representations of words
from large text corpora based on their co-occurrence patterns. These representations allow LLMs
to process language more accurately and nuancedly by helping them comprehend the context and
meaning of words. To illustrate this concept, authors in (Bandyopadhyay et al., 2022) projected a
number of word embeddings in 3D space to make it easier to grasp the idea of word embeddings
(figure 1.3).
Word embeddings proved to be very useful because of their following characteristics:
• Distributed representation: Word embeddings in a high-dimensional space express words
as vectors in a distributed representation. The features that represent each dimension of the
vector each represent a specific facet of the meaning of the word. Therefore, words with
comparable meanings or contexts tend to have vectors that are closer to one another in the
embedding space thanks to this distributed representation. For example, consider two words:
13

Figure 1.3: Plot of the projection of some word embeddings in a 3D space. The left and right
halves of the x-axis represent male and female words, respectively. Adult and youth words are,
respectively, in the top and bottom halves of the y-axis (Bandyopadhyay et al., 2022).
"dog" and "puppy." These words will likely have similar vector representations in a well-
trained LLM with word embeddings. For example, the representation of "dog" might be [0.2,
0.6, -0.3], while the representation of "puppy" might be [0.18, 0.58, -0.25]. The similarity in
the vector representations suggests that these are semantically close ideas.
• Analogies: Word embeddings also provide LLMs the ability to use analogical reasoning. For
example, given the analogy "man is to the woman as king is to ?," the LLM can infer the
missingword,"queen,"byleveragingthevectorrepresentationsofthewordsasshowninfigure
1.4
• Contextual embedding: When creating word representations, LLMs frequently use con-
textual embeddings like BERT (Bidirectional Encoder Representations from Transformers)
(Devlin et al., 2018), which take into account the surrounding words and sentence structure.
These contextual embeddings improve the model’s capacity to discern fine distinctions and
word meanings that are exclusive to a given context. For illustration, consider the sentence
"The bank is closed.". In this example, the word "bank" refers to a financial institution.
However, the word "bank" has an entirely different meaning in the sentence "He sat by the
river bank", where it refers to the river’s side. Because of contextual embeddings, the LLM
14

Figure 1.4: Word embeddings and analogy.
can distinguish between distinct word meanings based on the words and sentence structure
around them.
In addition to word embeddings, character embedding was also explored as a solution to deal
with morphologically complex and out-of-vocabulary words. In contrast to word embeddings,
which represent semantic relationships between words based on their context, character em-
beddingsrepresentindividualcharacters. Insteadofrelyingsolelyonpre-trainedwordvectors,
character embeddings enable models to generate embeddings for unobserved words by taking
into account the constituent characters. Techniques used to learn meaningful representations
from character sequences include character-level convolutional neural networks (Zhang et Le-
Cun,2015)andrecurrentneuralnetworkslanguagemodels(RNN-LM)(Kimet al.,2016;Joze-
fowicz et al., 2016). These embeddings can capture useful information about prefixes, suffixes,
and stems, allowing models to manage word variations and orthography inconsistencies more
effectively. By combining word and character embeddings, languagemodels can obtain a more
robust understanding of natural language.
To effectively leverage the powerful word representations in LLMs, such as word embeddings,
a groundbreaking architecture called the Transformer (Vaswani et al., 2017) was published in
2017, revolutionizing the field of Natural Language Processing.
1.4.2 The transformer architecture
Since its release in 2017, the Transformer architecture (Vaswani et al., 2017) has had a signifi-
cant impact on how LLMs are created and has been the underlying base of most new language
15

models. In the seminal paper "Attention Is All You Need", Vaswani et al. introduced a
machine learning architecture that overcame the drawbacks of sequential models like Recur-
rent Neural Networks (RNNs) (Rumelhart et al., 1985) and revolutionized natural language
processing tasks, including chatbot development.
Figure 1.5 shows the transformer architecture as illustrated in their original paper (Vaswani
et al., 2017). We also provide a brief overview of the essential aspects of this architecture as
well as its significance in the context of LLMs:
– Self-Attention Mechanism: The Transformer architecture employs a self-attention
mechanism that enables the model to evaluate the relative weights of several words or
tokens within a sequence. By utilizing this technique, the model is able to overcome the
constraintsofsequentialprocessingandcapturelong-rangedependenciesandinteractions
between words. Each word applies attention weights that it has acquired during training
to all other words, including itself. This mechanism considers the words’ positions and
captures contextual relationships between them.
– Attention Layers: The Transformer architecture consists of multiple attention layers.
Multiple self-attention heads are present in each layer, and they learn various represen-
tations of the input sequence separately. These attention heads’ outputs are merged and
altered to create a rich and varied collection of characteristics for the following layers.
– Positional Encoding: Using positional encoding, The Transformer model integrates
word positional information. By including learned positional vectors into the word em-
beddings, positional encoding informs the model of the placements of the words within
the sequence. This enables the model to distinguish words not just according to their
semantic meaning but also according to their location.
– Encoder-Decoder framework: Thisframeworkisusedinthetransformerarchitecture
in order to allow the model to generate coherent and contextually appropriate responses.
The encoder analyses the input sequence while employing self-attention layers to capture
contextual information, while the decoder pays attention to the encoder’s output and the
partial output sequence generated.
– Parallel Computation: Thanks to the transformer architecture, highly parallel com-
puting is made possible. The self-attention mechanism removes the sequential bottleneck
seen in conventional recurrent models, enabling the model to analyze all words in the
16

Figure 1.5: The transformer architecture (Vaswani et al., 2017).
17

sequence simultaneously. Large-scale language models can significantly benefit from the
improved training and inference efficiency of this parallel processing.
Building upon the advancements in LLMs, a very notable example that has gained considerable
attention in the field of chatbot development is ChatGPT, a state-of-the-art conversational AI
model developed by OpenAI.
1.5 Emotional Intelligence
1.5.1 Definition
Emotional intelligence is a concept rooted in psychology that plays a fundamental role in human
communication and interaction. It can be defined as "the ability to monitor one’s own and others’
feelings,todiscriminateamongthem,andtousethisinformationtoguideone’sthinkingandaction"
(Salovey et Mayer, 1990).
1.5.2 Emotion models
A well-known psychologist named Dr. Robert Plutchik introduced in 1980 a thorough model of
emotions called the "Plutchik’s Wheel of Emotions" (Plutchik, 1980), which seeks to explain and
categorize the complex range of human emotions. The model visualizes emotions as a wheel, with
eight primary emotions positioned at cardinal points and additional secondary emotions placed
between them to represent blended or mixed emotions (see figure 1.6). The eight basic emotions
represented are:
• Joy: The emotion associated with happiness, contentment, and pleasure.
• Sadness: The feeling of unhappiness, grief, or sorrow.
• Anger: The emotion characterized by hostility, frustration, or rage.
• Fear: The response to perceived threats or danger leading to anxiety or panic.
• Trust: The feeling of confidence, reliance, and belief in someone or something.
• Disgust: The aversion or revulsion towards something offensive or repulsive.
18

Figure 1.6: Plutchik’s wheel of emotions (Plutchik, 1980).
• Surprise: The emotion resulting from unexpected or startling events.
• Anticipation: The anticipation or excitement towards future events or possibilities.
Plutchik’s model also includes the concept of intensity, where varying degrees of intensity result in
a spectrum of emotions. For instance, joy can range from mild contentment to extreme ecstasy.
By combining and blending these primary emotions, Plutchik’s model provides a framework for
understanding and categorizing the complexities of human emotional experiences.
Later in 1992, Dr. Paul Ekman, the renowned psychologist and pioneer in the field of emotion
research, introduced another emotion model based on the "Facial Action Coding System" and
identified six common facial expressions of emotions. (Ekman, 1992). According to Ekman’s theory,
six primary emotions may be identified by their facial expressions: joy, sorrow, anger, fear, surprise,
and disgust. According to Ekman’s study, these emotional expressions are shared by all civilizations
and social groups, indicating that they are intrinsic and physiologically based. The Facial Action
CodingSystemthoroughlyexaminestheprecisefacialmusclemovementsconnectedtoeachemotion,
19

enabling accurate measurement and identification.
In the realm of AI, incorporating emotional intelligence into chatbots holds great promise for creat-
ing more engaging and empathetic conversational agents. We can narrow the communication gap
between humans and machines and make encounters that are more meaningful and rewarding by
giving chatbots the ability to recognize, understand, and respond to emotions.
1.6 Conclusion
Inconclusion, thischapterhasprovidedacomprehensiveoverviewofthefoundationalconceptsthat
underlie our research into enabling chatbots to engage in human-like conversations. We began by
exploring the realm of chatbots, showing their significance and offering insights into their architec-
ture design and natural language understanding capabilities. We also explained some techniques
used by modern LLMs as well as some emotion modeling methods.
In the next chapter, we will dive deeper into chatbot evolution in the last decades with a particular
focus on a recent disruptive chatbot: ChatGPT. We will also explore the challenges in equipping
artificialchatbotsystemswithhuman-likeemotionsandthedifferenttechniquesresearcherspropose
to tackle such a problem and make conversations more natural and engaging.
20

CHAPTER 2
LITERATURE REVIEW
2.1 Introduction
In recent years, the field of conversational systems has made tremendous strides, with language
models exhibiting astonishing skills in producing information-rich replies. However, understand-
ing and utilizing emotions is a significant obstacle to developing interactions that are genuinely
interesting and realistic. In this literature review, we start with a brief history of chatbot research
and development, then examine the methods that have been done to improve the emotional intelli-
gence of conversational language models. We aim to investigate the state-of-the-art approaches and
techniques used to comprehend and provide emotionally appropriate responses in human-machine
interactions. We analyze prior research in this area in order to find gaps, constraints, and opportu-
nities for further development.
2.2 A Brief History of Chatbots
The first chatbot in the literature was proposed in 1966 by Dr. Joseph Weizenbaum at the Mas-
sachusetts Institute of Technology (MIT), and it was called ELIZA (Weizenbaum, 1966). It was
designedtoplaytheroleofadigitalpsychotherapistandpavedthewayformanychatbotstofollow.
Chatbot development has since evolved from rule-based systems to more advanced generative AI
models.
2.2.1 Rule-based and pattern-matching systems
Rule-based chatbot systems were the leading technology used in the early stages of chatbot develop-
ment, including ELIZA (Weizenbaum, 1966). These systems generated answers based on specified
input criteria by following human-established rules and patterns. A rule-based system’s advantage
is that it can give accurate responses. However, it works well only when the input message is
well-formed. They had limited language understanding capabilities, and substantial manual pro-
gramming was necessary.
In 1995, ALICE (Artificial Linguistic Internet Computer Entity) was introduced, and it won the
21

Loebner Prize as “the most human computer” at the annual Turing Test contests in 2000, 2001, and
2004 (Wallace, 2009). It was the first personality program based on AIML (Artificial Intelligence
Markup Language), which allowed for the creation of more sophisticated and flexible chatbots by
defining patterns and predefined responses to engage in conversations on various topics. In fact, the
knowledge of the robot is represented in AIML via a set of categories. A pattern, which is the user’s
input, and a template, which is the bot’s response, make up each category. A word, a phrase, or
even a more generic pattern employing wildcard characters can be used as the pattern. The input
is compared to the predefined patterns when a user interacts with the chatbot, and the relevant
template is then chosen to produce the answer.
2.2.2 Retrieval-Based Systems
These systems rely on predefined responses stored in a knowledge base. They emerged as an im-
provement over previous technology with newer NLP techniques such as similarity metrics to match
user inputs to predefined patterns (Almansor et Hussain, 2020). These systems used predetermined
responses stored in a database and used keyword matching or similarity measurements in order to
pick the most acceptable replies for the user input. These techniques are used in personal assistants
like Alexa, Siri, and Google Assistant to fulfill user requests by gathering data from a variety of
sources (Bilquise et al., 2022). However, these systems have limited flexibility and use, especially
when domain-specific responses are required (Suhaili et al., 2021).
2.2.3 Sequence-to-sequence models and Generative AI
Generative-based chatbots, as opposed to limited, retrieval-based, and rule-based systems, usually
use an encoder-decoder design, specifically a sequence-to-sequence (seq2seq) architecture (Sutskever
et al., 2014). In fact, since Google researchers published their innovative seq2seq model in 2014, a
multitude of chatbot architectures based on seq2seq were proposed in the literature thanks to the
great potential it showed (Vinyals et Le, 2015).
Simply put, this model works by trying to predict the next sentence in a conversation on the basis
of the previous sentences using two Recurrent Neural Networks as encoder and decoder:
• Encoder: It processes the input sequence (user query) and transforms it into a fixed-length
22

vector representation known as the context vector. This allows for capturing the input’s
semantic and contextual details.
• Decoder: Itcreatestheoutputsequence(thechatbotanswer)wordbywordusingthecontext
vectorasinput. Basedonthecontextandthepreviouslycreatedwords,itguessesthefollowing
word that is most likely to occur.
Even though seq2seq was regarded as the industry’s best practice because it maximizes the like-
lihood of the answer and can analyze a lot of data to generate replies (Pamungkas, 2019), newer
architecturesmanagedtoimprovechatbotsevenfurther. Researchersarguedthatforaconversation
to be natural, a chatbot should respond on the basis of the current user query but also use previous
queries as well (Cahn, 2017). To achieve this, Long Short Term Memory (LSTM) (Hochreiter et
Schmidhuber, 1997) based architectures were used in chatbots to refer to previous information and
learn long-term dependencies. Using LSTM achieved good results when designing a conversational
agent for elderly care (Su et al., 2017) for instance. Other researchers used LSTM for response
generation instead (Xu et al., 2017). They used word2vec to represent user queries with vectors and
2 LSTM networks, one as an encoder and the other as a decoder.
In a broader sense, Generative AI, be it based on seq2seq models as used in (Belainine et al., 2022)
or other advanced architectures, can produce outputs that are not limited to predefined options
or fixed sets of responses (Bail, 2023). This is because they generate responses by modeling the
probability distribution of the next word or sequence of words given the context. However, one
limitation of generative models is the need for massive training data. This led to the development
of chatbots being dominated by open-domain systems because of publicly-available open-domain
data (Bilquise et al., 2022).
The Transformer architecture published in 2017 (Vaswani et al., 2017) is considered one of the most
important milestones in chatbot development and language models in general because it drastically
changed the way newer chatbots are designed. This new architecture helped language models
better understand the relationships and dependencies in input sequences by using techniques such
as attention mechanisms and self-attention layers. Through the use of intensive pre-training on
enormous volumes of text input, LLMs based on the Transformers architecture like OpenAI’s GPT
(Radfordet al., 2018)considerablyimprovedchatbotcapabilitiesgeneratinginterestingandoriginal
23

interactions. The transformer model was explained more in-depth in section 1.4.2, and in the rest
of this literature review, we are going to focus primarily on chatbots that are generative-based since
it is now the dominating approach to building modern chatbots (Pamungkas, 2019).
2.3 Chatbot Application Architecture
Thereareseveralchatbotarchitecturaldesignsproposedintheliterature. However,somearespecific
to retrieval-based chatbots (Wu et al., 2016) or to rule-based conversational agents (Khanna et al.,
2015). Morerecently, (AdamopoulouetMoussiades, 2020a)proposedageneralchatbotarchitecture
that is valid for retrieval-based systems, rule-based systems as well as generative-based chatbot
systems. It includes five main components:
User interface (UI) This component is the part that is exposed to the user and in which the
chatbot collects the requests/questions and shows answers. It can be a mobile app, a web app, or a
conversation inside an established instant messaging application. The UI needs to be well-designed
and simple to use if we want the users to be satisfied with the interaction (Gnewuch et al., 2018).
User Message Analysis This component preprocesses the user input and includes a spell checker
to correct spelling mistakes, a machine translation model if the chatbot is multilingual, and a
sentiment analysis/emotion recognition module to detect users’ psychological state.
Dialog Management Sometimes, the user’s input is insufficient to determine the context. In such
cases, the chatbot can ask additional questions to collect contextual information. This component
is helpful in handling ambiguity, collecting data about the user, and correcting potential errors.
Backend After processing the user’s input, the chatbot connects to a database to retrieve the
necessary information for a proper response. Ontologies like Wordnet (Miller, 1995) can be used at
this point to find connections between nodes in the knowledge graph and, therefore, "understand"
the meanings and relationships between words.
Response Generation Depending on the nature of the chatbot, this component uses a specific
technique to generate the best response to the user’s request using the information collected from
previous components. Generative, machine learning-based chatbots, in particular, use Natural
24

Figure 2.1: A general architecture design for chatbots (Adamopoulou et Moussiades, 2020a).
25

Language Generation (NLG) modules to respond in a natural, human-like fashion. As discussed
earlier, this needs a big training dataset to achieve good results. The response is presented through
the user interface, and the chatbot waits then for the following query.
2.4 Prompt engineering and language models
2.4.1 Prompt engineering
The exceptional performance of Large Language Models (LLMs) on a variety of tasks, even with
zero-shot or few-shot settings, has inspired NLP researchers to reevaluate the predominant training
paradigms from previous years, and prompt engineering is an excellent example of that. Prompt
Engineeringcanbedefinedasthedesignofinstructions(prompts)inawaythatimprovesthequality
of the results from existing language models without further training on new datasets (Reynolds
et McDonell, 2021). This is a relatively new and promising technique that appears to have the
potential to greatly improve LLMs’ performance on downstream tasks.
Many researchers leveraged the art of prompt engineering to effectively instruct language models
leading to the desirable results. For example, in the context of zero-shot mathematical reasoning,
(Kojima et al., 2022) found that simply prompting GPT-3 language model with "Let’s think step
by step" after the mathematical question quadrupled the accuracy on the MultiArith arithmetic
dataset, from 18% to 79%! The authors noted, however, that this method works well only with
arithmetic problems that need multiple steps and did not really help with commonsense questions,
for example. Prompt engineering was also used to improve neural machine translation (Li et al.,
2022). It was shown that leveraging prompts does help with the quality of the translations and
enhances the flexibility of human-in-the-loop translations.
Authors in (Wei et al., 2022) investigated chain-of-thought (CoT) prompting as a simple and gen-
erally applicable method to enhance reasoning abilities in LLMs. To produce a human-like thought
process and improve reasoning, they used CoT prompting with language models by including a
few examples of chain-of-thought using only prompts instead of fine-tuning as (Cobbe et al., 2021)
did. This resulted in improvements across a variety of tasks, such as arithmetic, commonsense, and
symbolic reasoning tasks. For instance, on grade school math problems, it was shown that chain of
thought prompting tripled the solve rate from 18% to 57%. Selection-inference prompting is later
26

proposed as an extension to Chain-of-Thought prompting (Creswell et al., 2022). It consists of di-
viding the single question prompt for generating explanations and answers into multiple questions:
A selection prompt first selects a pertinent subset of facts from the text. Then, a second inference
prompt draws a conclusion from the data chosen. These prompts are then alternated in a sequence
to generate multiple reasoning steps and, ultimately, the final answer. The authors showed that
selection-inference prompting outperformed chain-of-thought prompting on bAbi and Proof Writer
benchmarks.
Prompt engineering was also used with conversational language models. For example, (Polak et
Morgan, 2023) proposed ChatExtract as a prompt-engineering-based method that works even with
limited background to fully automate accurate data extraction from research papers. The set of
engineered prompts applied to a conversational LLM not only extracts the relevant data but also
verifies the data’s correctness through a series of follow-up questions, overcoming known issues with
LLMs like providing factually inaccurate responses (Lee et al., 2022). (White et al., 2023) even
proposed an entire prompt engineering patterns catalog to get the most out of ChatGPT (OpenAI,
2022). Thecatalogconsistsofover15promptpatternsdesignedforavarietyoftasks,suchasoutput
customization and context control, leading to improved output from the conversational language
model for different domains and contexts. It doesn’t include emotion or tone control prompts,
though.
Emotion stimuli through prompt engineering has also been used to enhance the responses of Large
Language Models. In (Li et al., 2023), researchers explored the integration of emotional intelligence
into several Large Language Models to see its impact on understanding performance. Automatic
experiments on 45 tasks involving language models, such as Flan-T5-Large (Chung et al., 2022),
Vicuna (Zheng et al., 2023), Llama 2 (Touvron et al., 2023), BLOOM(Workshop et al., 2022) and
ChatGPT (OpenAI, 2022), reveal that LLMs indeed possess a grasp of emotional intelligence. The
introduction of "EmotionPrompt," a fusion of the original prompt with emotional stimuli, leads to
notable improvements, including an 8% relative performance boost in Instruction Induction and a
remarkable 115% improvement in BIG-Bench with more improvements in few-shot settings when
compared to zero-shot settings. They also conducted a human study, involving 106 participants
and found that their technique achieves up to 1.0 in Relative Gain in a third of the problems. The
authors also noticed that EmotionPrompt stimulates the creative faculties of LLMs. In terms of
27

truthfulness, and responsibility metrics, LLMs prompted with EmotionPrompt showcased 19% and
12% of average improvements in truthfullness and informativeness scores. Researchers attributed
theseimprovementstothefactthatemotionalstimulicanenrichtheoriginalprompts’representation
and positive words in the prompts might have contributed too. They concluded their work by
acknowledging that, while LLMs can be enhanced by emotional intelligence, there are still mysteries
to unravel, leaving room for further exploration at the intersection of LLMs and psychology.
2.4.2 Dialogue models
Conversational language models (or dialogue models) have received a lot of attention in recent years
(Zaib et al., 2020). We can distinguish three main categories of these dialogue systems based on
their functionality:
• Task-oriented systems are developed to have dialogues with users to carry out a specific
task. These systems can be found in voice-based user interfaces, virtual assistants, and cus-
tomer support.
• Question-answeringsystemsareintendedtoprovidespecificanswerstouserqueries. These
systems aim to extract relevant information from a given knowledge source or corpus.
• Open-domain chat agentsaredesignedtoengageinopen-endeddiscussionswithusersover
various subjects. Open-domain chat-oriented systems try to create human-like and engaging
interactions, unlike task-oriented dialogue systems that concentrate on completing specified
tasks.
Many conversational systems based on Large Language Models (see section 1.4) were proposed in
the literature, and most of them are based on the Transformer architecture (Zaib et al., 2020).
For instance, the DialoGPT (Zhang et al., 2019) model was trained on 147 million conversation-
like exchanges extracted from Reddit comment threads. Thus, it is a conversation language model
that has encoding for the dialogue structure knowledge within their parameters. However, there is
a recent, disruptive conversational language model that has taken the internet by storm since its
introduction: ChatGPT (OpenAI, 2022).
28

2.4.3 ChatGPT
ChatGPT (OpenAI, 2022) is a Large conversational Language Model based on the GPT-3.5 archi-
tecture and developed by OpenAI (Ouyang et al., 2022). Since its release as an online platform in
November 2022, it has received a lot of attention from the public as well as from researchers.
Since its debut, ChatGPT has attracted a record 100 million subscribers in only two months, over-
coming other very popular online platforms such as Facebook and Instagram (Haque et al., 2022).
ChatGPT reached the 1 Million user mark within five days only, whereas Instagram, Facebook, and
Netflix needed 75, 300, and 1200 days to reach the same number (Haque et al., 2022), respectively.
2.4.3.1 A (mostly) well-received newborn
The feedback around ChatGPT has been mostly positive from the public on social media and news
outlets (Leiter et al., 2023). Haque et al. (Haque et al., 2022) examined how well the new chatbot
was received using sentiment analysis on Twitter data and found that the social media platform
users exhibited positive sentiments when talking about ChatGPT for topics such as entertainment,
NLP, and software development with positive sentiments representing up to 92%, 83%, and 82%
respectively. On the other hand, the topics in which users showed the least positive sentiments were
Q&A testing and impact on the educational aspect, with only 38% and 54% of the tweets being
positive, respectively. This indicates that, even though the feedback was mostly positive, some were
concerned about the implications of ChatGPT on the future of education and information integrity
and reliability.
While regular users enjoyed its features and have been using it to accomplish a variety of tasks,
researchers were interested in studying this technology and exploring its capabilities and limits in
multiple aspects.
2.4.3.2 A disruptive technology
ChatGPT’s success can be attributed to its ability to converse with humans in various natural
language tasks; from straightforward queries to more complicated dialogues in an incredibly fluent
and coherent fashion (Guo et al., 2023). Here are some of the features that made ChatGPT so
engaging to users that it reached record-breaking adoption rates:
29

• Contextual Understanding: ChatGPT exhibits a good capacity for comprehension and
context maintenance during discussions. In order to provide logical and contextually appro-
priate replies, it may draw on the complete conversation history instead of only considering
the last user utterance. This leads to more interesting and organic interactions with users.
• Natural Language Generation: Thankstoitsthoroughtrainingonvariousdatasets,Chat-
GPT excels at producing writing that sounds human. By using the statistical patterns and
linguistic structures it has acquired throughout training, it may provide comprehensible and
appropriate replies for the given situation.
• Creative and Dynamic Responses: ChatGPT is renowned for its capacity to produce
original replies, which can enhance user engagement. It can make ideas, come up with logical
extensions, or even have imaginary talks about particular subjects.
Even though OpenAI has never published the technical details and specific architecture, we already
know some techniques that helped achieve such an impressive system. The model was trained on a
massive corpora blend of text and code (Neelakantan et al., 2022) and continuously improves using
Reinforcement Learning from Human Feedback (RLHF) (Stiennon et al., 2020; Christiano et al.,
2017), which has become the go-to technique to align LLMs with a human’s actual intent.
(Zhou et al., 2023) explain the RLHF approach used in ChatGPT as follows: First, an extensive
dataset, including prompts and the expected output behaviors, is collected, and GPT-3.5 is run on
this data. Then, the refined model provides a variety of model outputs in response to the same
prompt. To create a comparison dataset, a labeler assigns the required score and ranks the output,
which is then utilized to train the reward model. Finally, using the Proximal Policy Optimisation
(PPO) RL (Reinforcement Learning) algorithm, the fine-tuned model, ChatGPT, in this case, is
optimized against the reward model. See 2.2 for an illustration of this process.
2.4.3.3 ChatGPT Under the Spotlight
There has been a growing interest among researchers in evaluating the new conversational lan-
guage model to find how well it copes with different tasks, from machine translation to coding and
reasoning.
30

Figure 2.2: How reinforcement learning from human feedback is used for ChatGPT (Zhou et al.,
2023).
In Machine translation, a study found that ChatGPT outperforms professional translation tools
for high-resource European languages, but for low-resource or far-off languages, it falls short (Jiao
et al., 2023). The use of pivot prompting (translating to a high-resource language before translating
that to the target language) greatly enhances translation performance. However, their findings
indicate that ChatGPT is not as reliable as commercial systems for biological abstracts or Reddit
comments. Using the GPT-4 as the engine dramatically improves the translation results, especially
for low-resource languages.
Another study examined ChatGPT’s accuracy in translating between English and languages that
exclusively use gender-neutral pronouns like Bengali (Ghosh et Caliskan, 2023). They found that
ChatGPT shares similar gender biases as other translation tools. In fact, it turns out ChatGPT
assignsgenderedpronounsbasedonbiasesandpreconceptionsassociatedwithparticularprofessions
andbehaviors. Additionally,itmistranslatesthepronoun"they,"whichisgender-neutral,leadingto
incorrect interpretations, and when asked about gender, ChatGPT shows greater respect for males
than women in the same profession.
However, a team participating in the AmericasNLP 2023 Shared Task on Machine Translation into
Indigenous Languages found that ChatGPT performs very poorly on translating to these south
american languages (Stap et Araabi, 2023). They submitted translations for 11 languages using
four different systems including a GPT-4 ChatGPT model. The latter didn’t outperform any other
modelonanyindigenouslanguage,showingthatitisnotwellsuitedfortheselow-resourcelanguages.
Text summarization is another task for which ChatGPT was tested. Researchers found that,
even though ChatGPT does give excellent results in terms of ROUGE score, it was outperformed
31

by GPT-3.5 and tended to produce more extended summaries (Qin et al., 2023). (Bang et al., 2023)
found that ChatGPT, with zero-shot, even outperforms some fine-tuned language models but with
zero-shot. However, they found that this is not consistent as it sometimes outputs a text summary
that is longer than the original text, for example.
Other researchers conducted an evaluation of ChatGPT’s aspect and query-based summarization,
which is more complex than generic summarization and requires a deeper level of understanding.
The results showed that ChatGPT performs on par with conventional fine-tuning techniques on
diverse benchmark datasets, including summaries from Reddit postings, news articles, conversation
meetings, and tales (Yang et al., 2023).
Anotherstudy(PuetDemberg, 2023)exploresChatGPT’stextgeneratingcapabilitiesintaskssuch
as text summarization. They found out that ChatGPT is not as good as humans at catching the
depth of stylistic variances. It has fewer ranges and sometimes makes factual mistakes or hallucina-
tions. The study’s quantitative and qualitative experiments demonstrate that, despite ChatGPT’s
superior performance when compared to earlier models in automated metrics, human-written text
and its output still differ significantly. These discrepancies are mitigated by offering a target exam-
ple of a human writing style; yet, problems like errors and hallucinations continue to appear in text
created by ChatGPT.
Reasoning and mathematical capabilitieswerealsothoroughlyexaminedbyresearchers. Chat-
GPTcanmakelogicalconnectionsanddrawconclusionsbasedontheinformationprovided, proving
that it does have reasoning abilities. It was shown that ChatGPT has impressive arithmetic rea-
soning abilities, outperforming GPT-3.5 in 5 out of the six datasets the researchers used (Qin et al.,
2023). However, they showed that it wasn’t the case with common sense and logical reasoning.
Authors in (Frieder et al., 2023) examined ChatGPT’s mathematical capabilities and found that,
contrary to the media hype, ChatGPT is not ready to consistently deliver top-notch proofs or cal-
culations in advanced mathematics, yet. However, there are positive surprises in the quality of
answers. It was shown that the language model still falls short on graduate-level difficulty. Chat-
GPT is found to be inconsistently proficient in advanced math, excelling in some insightful proofs
butgenerallystrugglingwithdifficultproblems. Itisnotonparwithtask-specificmodelsbutshines
in flexibility, serving as a universal tool for diverse mathematical areas.
32

In Programming and coding, ChatGPT can be used as a programmer’s helper, offering rec-
ommendations for code, troubleshooting, and clarifying programming concepts. ChatGPT was
evaluated in terms of bug-fixing efficiency on the QuixBugs dataset and was compared to other
methods proposed in the literature (Sobania et al., 2023). The results showed that ChatGPT out-
performsstandardprogramrepairtechniquesandcompetesfavorablywithwell-knowndeeplearning
techniques like CoCoNut and Codex.
Moreover, ChatGPT, thanks to its conversational nature, allows users to provide additional infor-
mation, such as expected outputs or observed error messages, for further assistance. This feature
helped ChatGPT to surpass state-of-the-art techniques.
A technical report (Kashefi et Mukerji, 2023) analyzed the numerical programming capabilities of
ChatGPT. They showed that the language model has the capacity to create programs in several
programming languages, improve and debug code, finish off missing portions, and even parallelize
C++ routines using OpenMP. However, the authors found that ChatGPT has some difficulties in-
cluding the creation of singular (non-invertible) matrices, the management of arrays of compatible
shapesetc. Moreover, itturnsoutChatGPTstrugglestoidentifyifacodeportionishuman-written
or ChatGPT-generated.
ChatGPT was also examined in terms of Sentiment analysis capabilities, and it largely outper-
formed state-of-the-art zero-shot models in English and Indonesian and performed just as well in
Buginese (Bang et al., 2023). Another study found that ChatGPT exhibited similar performance
when compared to BERT on the same sentiment analysis task (Zhong et al., 2023). It was also
shown that its performance is comparable to GPT-3.5 (Qin et al., 2023). In another, more in-depth
article, researchers tested ChatGPT on five sentiment analysis tasks with 18 benchmarking datasets
and found that it has a similar performance to fine-tuned BERT, without being fine-tuned itself
(Wang et al., 2023). They also demonstrated that giving a couple of examples to the chatbot (few-
shotlearning)helpedthemodelimproveevenfurther, eventhoughitdidn’tsignificantlyoutperform
state-of-the-art fine-tuned models.
(Lai et al., 2023) evaluated the performance of ChatGPT, beyond English, on many NLP tasks such
as NER, NMT, POS, NLI, QA, and CSR. (Kocoń et al., 2023) tried to evaluate ChatGPT on 25
different NLP tasks and found that it did very well in most of them but didn’t outperform the state
of the art in any particular task.
33

The emotional capabilities of ChatGPT were studied as well. Through a series of trials on var-
ious downstream tasks such as emotion understanding and emotion generation, a study assessed
the effectiveness of ChatGPT on emotional conversation interpretation and creation (Zhao et al.,
2023). Their results showed that ChatGPT demonstrates promising outcomes in evoking emotional
reactions, even if its performance on emotional conversation interpretation may still lag below that
of supervised models.
In fact, ChatGPT showed promising results in the emotion generation capabilities, such as empa-
theticresponsegenerationandemotionalsupportconversationtasks, outperformingstate-of-the-art
models. However, it didn’t outperform state-of-the-art fine-tuned models on emotion understanding
tasks (emotion recognition, emotion cause recognition, and dialogue act classification). This shows
that more work can be done to enhance the emotion recognition capabilities of the model. To the
best of our knowledge, no work has been done yet to improve this aspect of ChatGPT.
Another recently published study (Wake et al., 2023) explored ChatGPT’s potential uses in data
annotation and mental health analysis by delving into its ability to identify emotions in text across
multiple datasets such as DailyDialogue (Li et al., 2017). The experiments conducted revealed a re-
spectable degree of emotion recognition reproducibility, with even more improvements seen through
fine-tuning. However, it turns out performance varies between datasets and emotion labels, sug-
gesting bias and intrinsic instability. The labeling techniques and training data biases are probably
behind this variation in recognition performance. The authors concluded that even though the lan-
guage model behind ChatGPT shows impressive proficiency, we need to be cautious when applying
such models in sensitive domains like mental health.
2.4.3.4 Concerns
ChatGPT has received a lot of attention and appreciation for its exceptional abilities to produce
human-like replies and carry out numerous language-related activities. However, the chatbot has
also sparked debate both inside and outside of the AI community.
One major concern is the potential for biases present in the data used for training ChatGPT,
leading to biased or discriminatory outputs. It was shown that ChatGPT exhibits gender bias,
especially with professions associated with particular genders (Ghosh et Caliskan, 2023). Another
articlepresentedacomprehensivestudyonthedifferentkindsofbiasesthatChatGPTcouldexhibit
and identified 24 sorts of biases: from cultural and linguistic bias to hindsight bias (Ray, 2023).
34

Moreover, ChatGPTtendstogenerateplausiblebutinaccurateinformation, alsoknownaslanguage
model hallucination (Lee et al., 2022). It was shown that ChatGPT suffers from intrinsic hallu-
cinations (output that contradicts the input) as well as from extrinsic hallucinations (output that
cannot be verified by the source), the latter being more frequent (Bang et al., 2023).
Another concern is related to education. While ChatGPT can enhance personalized learning and
facilitate access to knowledge, the conversational model was so good at producing human-like text
and at question answering that some considered it to be a threat to the future of exam integrity.
Some students are already using it to cheat in assignments (Susnjak, 2022).
2.5 Emotions in conversational systems
Emotions are states of feelings resulting from internal or external changes in our lives and depend
on the speaker’s attitude and personality (Al-Omari et al., 2020). Incorporating emotions into
conversational systems is a crucial step in making human-like conversational systems, even though
it can be challenging to achieve such a task.
2.5.1 The importance of emotions in conversational systems
Despite all the advancements the conversational agents’ research, it appears that people still prefer
natural communication to machine-like interactions and feel that a human can understand them
better (Rapp et al., 2021). Furthermore, it was shown that customers still prefer interacting with
humans over machines (Adam et al., 2021).
Infact,astudyshowedthatforcustomerservice,forexample,40%ofconsumers’requestsarerather
emotional without specific informational intents (Xu et al., 2017). Thus, building sympathetic and
successful conversational agents requires the capacity to recognize and respond to the emotional
cues that are present in all human dialogue.
However, generating empathetic and human-like responses is a challenging task for chatbots as it
requires an understanding of the complex user’s emotional state and the ability to respond appro-
priately. Much work was done to address this challenge of building emotion-aware conversational
systems, and it was shown that the interest particularly grew since the year 2018 and that most of
35

the solutions proposed in the literature were text-based conversational agents (Bilquise et al., 2022).
The first chatbot developed with emotions in mind, PARRY, dates back to 1971, and it was a
rule-based system that played the role of a patient with schizophrenia (Colby et al., 1971). It was
even tested later by multiple psychotherapists to see if they could determine if he was a bot or a
human (Heiser et al., 1979). Today, most emotionally aware chatbots are neural-based they mostly
use seq2seq and encoder-decoder architectures.
2.5.2 Challenges and techniques used for incorporating emotions into chatbots
Researchers tackling the problem of developing emotion-aware conversational systems have used
manytechniquesthataddressdifferentaspectsofhuman-likeandemotionally-awarechatbots. Some
of them worked on improving the detection of the user emotion, and others tried to generate emo-
tional responses better, while others tried to avoid the dull and meaningless responses generated by
basic seq2seq models.
2.5.2.1 Emotion Capture
Accurately identifying and comprehending emotions in user input is essential for developing emo-
tionally intelligent responses. However, given the complexity and subjectivity of emotions, it might
be challenging to identify them from writing. The proper recognition of emotions is further com-
plicated by variations in linguistic expression, sarcasm, and cultural quirks, making it difficult to
understand user input accurately.
(Casas et al., 2021) used DeepMoji (Felbo et al., 2017) as an emotion classifier to detect the user’s
emotionsandclassifythemfollowingEkman’smodelofsixbasicemotions(discussedinsection1.5.2)
before injecting them into the dialogue system. Other researchers tried to consider not only the last
user input’s emotion but instead use the conversation history. For instance, in the work of (Qiu
et al., 2020), the system tracks the user’s emotional state using a transition network. (Hasegawa
et al., 2013) claimed that predicting the user’s emotional state from past conversational utterances
rather than a single speech is the only way to accomplish genuinely natural conversation.
However, according to a number of studies, emotions are complex and cannot be adequately de-
36