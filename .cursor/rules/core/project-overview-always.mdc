---
description:
globs:
alwaysApply: true
---

# Systematic Review Automation Tool

## Project Identity
- **Purpose:** Automate systematic literature reviews to produce IEEE-submission-ready manuscripts
- **Stack:** Python 3.11+, PydanticAI Graph, SQLite, Google Gemini 2.5, statsmodels, matplotlib
- **Frontend:** React 19, Vite 7, TypeScript, Tailwind 4, Recharts, cmdk, Radix UI
- **Package manager:** uv (Python), pnpm (frontend)
- **Architecture:** Typed state, SQLite persistence, 3-tier LLM model selection, FastAPI web server

## Key Directories -- Backend
- `src/models/` -- Pydantic data contracts (enums, config, papers, screening, extraction, quality, writing, workflow)
- `src/db/` -- SQLite schema, connection manager, typed repositories
- `src/orchestration/` -- quality gates (gates.py), workflow graph (workflow.py), context (context.py), resume (resume.py), state (state.py)
- `src/search/` -- OpenAlex, PubMed, arXiv, IEEE, Semantic Scholar, Crossref, Perplexity auxiliary + dedup + strategy
- `src/screening/` -- Dual-reviewer screener, prompts, reliability (Cohen's kappa)
- `src/extraction/` -- agentic study classifier + baseline structured extraction scaffolding
- `src/quality/` -- baseline RoB 2, ROBINS-I, CASP, GRADE, study router
- `src/synthesis/` -- Meta-analysis (statsmodels), effect sizes, narrative fallback
- `src/writing/` -- Section writer, prompts, humanizer, style extractor, naturalness scorer
- `src/citation/` -- Citation ledger, BibTeX generation
- `src/prisma/` -- PRISMA 2020 flow diagram
- `src/protocol/` -- PROSPERO-format protocol generator
- `src/visualization/` -- Forest plot, funnel plot, RoB figure, timeline, geographic
- `src/export/` -- IEEE LaTeX, submission packager, PRISMA checklist validator
- `src/llm/` -- PydanticAI agent factory, rate limiter, cost tracking
- `src/web/` -- FastAPI backend (app.py): run lifecycle, SSE streaming, history, DB explorer, log streaming
- `src/utils/` -- logging_paths.py (PM2 log path detection), ssl_context.py, structured_log.py
- `scripts/` -- finalize_manuscript.py (IMRaD heading injection + post-run fixup), migrate_to_runs.py
- `config/` -- review.yaml (per-review) + settings.yaml (system behavior)

## Key Directories -- Frontend
- `frontend/src/views/` -- RunView (tabs: Activity, Results, Data, Cost), DatabaseView, CostView, HistoryView, SetupView, ResultsView
- `frontend/src/components/` -- Sidebar (drag-resize, resume), UI primitives (command.tsx, status-badge.tsx, table.tsx, feedback.tsx)
- `frontend/src/hooks/` -- useSSEStream (run events + SQLite replay fallback), useLogStream (backend log SSE)
- `frontend/src/lib/` -- api.ts (typed API layer), format.ts (date/duration helpers)

## Key Tables
- `workflows` (per-run runtime.db) -- topic, config_hash, status
- `workflows_registry` (central `{run_root}/workflows_registry.db`) -- workflow_id, topic, config_hash, db_path, status, heartbeat_at
- `event_log` (per-run runtime.db) -- SSE event replay buffer; fields: workflow_id, event_type, payload, ts

## Web API
- FastAPI backend on port 8001 (dev) / 8000 (prod), Vite dev server on port 5173
- Run lifecycle: POST /api/run, GET /api/stream/{run_id}, POST /api/cancel/{run_id}, GET /api/runs
- Results: GET /api/results/{run_id}, GET /api/run/{run_id}/artifacts, POST /api/run/{run_id}/export
- History: GET /api/history, GET /api/history/{workflow_id}/config, POST /api/history/resume, POST /api/history/attach
- DB explorer: GET /api/db/{run_id}/papers, /papers-all, /papers-facets, /papers-suggest, /screening, /costs
- Event replay: GET /api/run/{run_id}/events, GET /api/workflow/{workflow_id}/events
- Log streaming: GET /api/logs/stream?run_id={run_id} (SSE, per-run PM2 log tail)
- Config: GET /api/config/review, GET /api/health
- Stale detection: heartbeat updated every 60s; runs with no heartbeat for 5+ min become "stale"
- Concurrent resume guard: if same workflow_id already active, returns existing run_id (no duplicate task)

## Critical Constraints
- **Use `rich`** for CLI output (progress bars, tables, status)
- **Verify APIs** before embedding: use @Ref or Exa to check current docs for statsmodels, pydantic_graph, aiosqlite, etc. Do not embed outdated code patterns.
- **NO untyped dictionaries** at phase boundaries -- only Pydantic models
- **NO LLM-computed statistics** -- meta-analysis uses scipy/statsmodels only
- **ALL I/O is async** (aiosqlite, aiohttp)
- **ALL LLM calls logged** with model, tokens, cost, latency to cost_records table
- **Citation lineage enforced** -- every claim must trace to evidence to citation
- See `config/review.yaml` for per-review topic config, `config/settings.yaml` for agent models + thresholds

## Strict Commit Safety
- NEVER stage or commit `.env`, `runs/**`, or topic/run-specific generated artifacts unless user explicitly asks.
- Before any commit operation, verify staged files do not include secrets/runtime outputs and abort if they do.

<example>
# Good: Typed phase boundary
async def screen_paper(paper: CandidatePaper) -> DualScreeningResult:
    ...
</example>

<example type="invalid">
# Bad: Untyped dictionary crossing phase boundary
async def screen_paper(paper: dict) -> dict:
    ...
</example>
